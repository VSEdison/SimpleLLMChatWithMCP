# 支持MCP的LLM对话工具开发计划

## 项目概述
开发一个支持MCP（Model Context Protocol）的LLM对话工具，使用fastmcp库实现。该工具将能够：
1. 使用requests调用OpenAI格式的LLM API
2. 通过MCP协议提供工具调用能力
3. 支持从环境变量配置LLM API的URL、模型和密钥
4. 支持多组对话及管理功能

## 文件结构
- `.env` - 环境变量配置文件
- `mcp_server.py` - MCP服务器实现
- `mcp_client.py` - MCP客户端实现
- `run.py` - 主程序入口
- `mcpServers.json` - MCP服务器配置文件
- `requirements.txt` - 项目依赖项
- `app.py` - Quart异步应用
- `static/` - 静态资源目录
- `templates/` - 模板目录
- `conversations.db` - 对话数据库

## 开发任务

### 1. 环境变量配置文件 [已完成]
创建`.env`文件，包含以下配置项：
- `LLM_API_URL` - LLM API的URL
- `LLM_API_MODEL` - 使用的模型名称
- `LLM_API_KEY` - API密钥

### 2. MCP服务器实现 [已完成]
在`mcp_server.py`中：
- 使用FastMCP创建MCP服务器
- 实现必要的工具函数
- 配置服务器名称和说明

### 3. MCP客户端实现 [已完成]
在`mcp_client.py`中：
- 实现与LLM API的通信
- 处理MCP工具调用
- 实现对话历史管理

### 4. 主程序入口 [已完成]
在`run.py`中：
- 加载环境变量
- 初始化MCP客户端和服务器
- 实现命令行交互界面

### 5. MCP服务器配置文件 [已完成]
创建`mcpServers.json`文件，包含MCP服务器的配置信息。

### 6. 项目依赖项 [已完成]
创建`requirements.txt`文件，列出项目依赖项。

## 详细实现步骤

### 1. 环境变量配置文件
- 创建`.env`文件
- 添加LLM API配置项

### 2. MCP服务器实现
- 导入必要的库
- 创建FastMCP实例
- 实现工具函数
- 配置服务器运行方式

### 3. MCP客户端实现
- 导入必要的库
- 实现LLM API调用函数
- 实现MCP工具调用处理
- 实现对话历史管理

### 4. 主程序入口
- 导入必要的库
- 加载环境变量
- 初始化MCP客户端和服务器
- 实现命令行交互界面

### 5. MCP服务器配置文件
- 创建`mcpServers.json`文件
- 添加MCP服务器配置信息

## 测试计划 [已完成]
1. 测试环境变量加载
2. 测试LLM API调用
3. 测试MCP工具调用
4. 测试完整对话流程

## 依赖项 [已完成]
- fastmcp>=2.2.0
- requests>=2.28.0
- python-dotenv>=1.0.0

### 7. Quart异步网页界面 [已完成]
- 创建Quart异步应用
- 实现网页对话界面
- 添加静态资源（CSS、JavaScript）
- 实现前后端异步交互

### 8. 多MCP服务器支持 [已完成]
- 修改mcpServers.json，支持配置多个MCP服务器
- 修改MCP客户端，支持连接多个MCP服务器
- 实现工具调用的路由，将请求发送到正确的MCP服务器
- 整合来自不同MCP服务器的工具

### 9. 在前端显示当前可用工具 [已完成]
- 在app.py中添加新的API端点`/api/tools`，用于获取当前可用的工具列表 [已完成]
- 在前端添加工具列表显示区域 [已完成]
- 实现工具列表的展示和折叠功能 [已完成]
- 添加样式使工具列表美观易用 [已完成]

### 10. 添加网页内容解析MCP工具 [已完成]
- 创建`web_parser.py`模块，实现网页内容获取和解析功能 [已完成]
- 在`mcp_server.py`中添加新的工具函数`fetch_web_content` [已完成]
- 添加内容长度限制和格式化选项（纯文本/Markdown/HTML） [已完成]
- 更新系统提示词，指导LLM如何组合使用search_web和fetch_web_content [已完成]

### 11. 支持多次工具调用 [已完成]
- 修改`mcp_client.py`中的`process_message`方法，支持识别和处理多个工具调用 [已完成]
- 实现递归处理多个工具调用的功能 [已完成]
- 优化对话历史记录的管理，确保多次工具调用的上下文正确保存 [已完成]
- 更新系统提示词，告诉LLM它可以在一次响应中连续调用多个工具 [已完成]
- 改进工具调用处理逻辑，先获取所有工具调用结果，再一次性调用LLM处理 [已完成]

### 12. 将SSE切换为WebSocket [已完成]
- 修改app.py，添加WebSocket路由和处理逻辑 [已完成]
- 修改static/js/script.js，使用WebSocket API替代EventSource [已完成]
- 确保消息处理逻辑与现有实现兼容 [已完成]
- 添加WebSocket连接状态管理和重连机制 [已完成]

#### 12.1 修改app.py [已完成]
- 导入websocket相关模块
- 添加WebSocket路由`/api/ws`
- 实现WebSocket连接处理函数
- 确保WebSocket路由能够处理与SSE相同的消息格式

#### 12.2 修改static/js/script.js [已完成]
- 修改sendMessage函数，使用WebSocket替代EventSource
- 实现WebSocket连接建立、消息发送和接收逻辑
- 确保消息处理逻辑与现有SSE处理逻辑兼容
- 处理WebSocket连接错误和重连机制

#### 12.3 测试和调试 [已完成]
- 测试基本的消息发送和接收功能
- 测试特殊标签处理（思考过程、工具调用等）
- 测试错误处理和重连机制
- 确保与现有功能完全兼容

#### 12.4 清理代码 [已完成]
- 删除SSE相关的路由和处理函数
- 删除不必要的心跳机制代码
- 移除不再使用的导入和变量

### 13. 支持多组对话及管理 [进行中]
- 修改数据库结构，支持多个对话会话 [待完成]
- 修改后端API，支持创建、切换、删除对话会话 [待完成]
- 修改前端界面，添加对话会话列表和管理功能 [待完成]
- 实现对话会话的持久化存储 [待完成]

#### 13.1 修改数据库结构 [待完成]
- 添加会话表，存储会话信息（ID、名称、创建时间等）
- 修改对话表，关联到会话ID
- 添加会话管理相关的数据库操作函数

#### 13.2 修改后端API [待完成]
- 添加获取会话列表的API
- 添加创建新会话的API
- 添加切换会话的API
- 添加删除会话的API
- 添加重命名会话的API
- 修改现有的消息处理API，支持会话ID参数

#### 13.3 修改前端界面 [待完成]
- 添加会话列表侧边栏
- 实现会话切换功能
- 实现会话创建、删除、重命名功能
- 优化移动端适配

#### 13.4 实现对话会话的持久化存储 [待完成]
- 修改mcp_client.py，支持从数据库加载和保存对话历史
- 确保会话切换时正确加载对应的对话历史
- 实现会话数据的定期自动保存

## 项目总结
我们已经成功完成了支持MCP的LLM对话工具的开发。该工具具有以下特点：

1. 使用fastmcp库实现MCP服务器和客户端
2. 支持通过环境变量配置LLM API
3. 提供多种工具函数供LLM调用
4. 实现了命令行交互界面
5. 支持对话历史管理
6. 提供了Quart异步网页对话界面
7. 支持同时使用多个MCP服务器的工具
8. 支持折叠/展开LLM的思考过程和工具调用
9. 在前端显示当前可用的工具列表
10. 提供网页内容解析工具，配合search_web使用
11. 支持多次工具调用，允许LLM在一次响应中连续调用多个工具
12. 使用WebSocket进行流式传输，替代SSE，提供更好的双向通信体验
13. 支持多组对话及管理功能（进行中）

该项目展示了如何使用MCP协议扩展LLM的能力，使其能够执行各种工具函数，如获取当前时间、读写文件等。通过这种方式，LLM可以与外部世界交互，提供更加强大和实用的功能。

此外，我们还添加了一个基于Quart的异步网页界面，使用户可以通过浏览器与LLM进行对话，提供了更加友好的用户体验。Quart是Flask的异步版本，支持原生的异步处理，更适合处理需要长时间运行的任务。

我们实现了多MCP服务器支持，使系统能够同时使用本地和外部MCP服务器提供的工具。这大大扩展了系统的功能，使其能够利用各种专业工具，如Context7等。

最后，我们添加了对LLM思考过程（`<think></think>`标签）和工具调用过程的折叠/展开功能，使对话界面更加简洁，同时用户仍然可以在需要时查看详细信息。
